{"n_in": 7, "learning_rate": 0.0004991066534650134, "hidden_layers_sizes": [20, 20, 20], "lr_decay": 0.000746533203125, "momentum": 0.8255483398437501, "L2_reg": 1.5917993164062498, "L1_reg": 0.0, "activation": "selu", "dropout": 0.0783935546875, "batch_norm": false, "standardize": true}